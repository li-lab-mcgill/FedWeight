{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mikezhu\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-08T07:46:12.670324Z",
     "start_time": "2024-12-08T07:46:12.126578Z"
    }
   },
   "id": "f3e541c1a94afce0",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('database is locked')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Change the directory to your scratch folder\n",
    "os.chdir('/scratch/mikezhu/fed_weight_jupyter/notebook')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-08T07:46:17.153368Z",
     "start_time": "2024-12-08T07:46:12.641629Z"
    }
   },
   "id": "92332044883daac1",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/mikezhu/fed_weight_jupyter/notebook\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-08T07:46:17.250479Z",
     "start_time": "2024-12-08T07:46:17.151466Z"
    }
   },
   "id": "6f5f5a1086faa6c1",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "random_seed = 42\n",
    "torch.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-08T07:47:17.930725Z",
     "start_time": "2024-12-08T07:46:17.249018Z"
    }
   },
   "id": "840ed0370e7ba29e",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "rho_size = 512\n",
    "num_topics = 64\n",
    "t_hidden_size = 512\n",
    "enc_drop = 0.2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-08T07:47:17.969949Z",
     "start_time": "2024-12-08T07:47:17.924624Z"
    }
   },
   "id": "c374ca690fdd43e8",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "icd_data = pd.read_csv(\"../data/eicu_mimic_patient_diagnosis.csv\")\n",
    "\n",
    "hospital_ids = [2001, 1001]\n",
    "\n",
    "readmit_interval_threshold = {\n",
    "    2001: 180, # Whether MIMIC patients will readmit to hospital within 180 days\n",
    "    1001: 2 # Whether eICU patients will readmit to ICU within 2 days\n",
    "}\n",
    "\n",
    "train_epochs = {\n",
    "    2001: 100,\n",
    "    1001: 100\n",
    "}\n",
    "\n",
    "train_loaders = {}\n",
    "train_icds = {}\n",
    "test_icds = {}\n",
    "x_bow_tests = {}\n",
    "\n",
    "train_readmit_row_ids = {}\n",
    "test_readmit_row_ids = {}\n",
    "\n",
    "train_label_deaths = {}\n",
    "test_label_deaths = {}\n",
    "\n",
    "train_label_readmit = {}\n",
    "test_label_readmit = {}\n",
    "\n",
    "for hospital_id in hospital_ids:\n",
    "    \n",
    "    hospital_data = icd_data[icd_data[\"hospitalid\"] == hospital_id]\n",
    "    train_data, test_data = train_test_split(hospital_data, test_size=0.2, random_state=42)\n",
    "    \n",
    "    x_train = train_data.iloc[:, 4:].to_numpy()\n",
    "    x_test = test_data.iloc[:, 4:].to_numpy()\n",
    "    \n",
    "    x_train_tensor = torch.tensor(x_train, dtype=torch.float32).to(device)\n",
    "    x_test_tensor = torch.tensor(x_test, dtype=torch.float32).to(device)\n",
    "    \n",
    "    train_dataset = TensorDataset(x_train_tensor, x_train_tensor)  # Use the same tensor for inputs and targets\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=False)\n",
    "    train_loaders[hospital_id] = train_loader\n",
    "    \n",
    "    train_icds[hospital_id] = x_train_tensor\n",
    "    test_icds[hospital_id] = x_test_tensor\n",
    "    \n",
    "    # Bag of words\n",
    "    x_bow_test = []\n",
    "    for row in x_test:\n",
    "        word_id = list(np.where(row == 1)[0])\n",
    "        x_bow_test.append(word_id)\n",
    "    x_bow_tests[hospital_id] = x_bow_test\n",
    "    \n",
    "    # Readmission patients row ids\n",
    "    train_data_np = train_data.to_numpy()\n",
    "    train_readmit_patients_row_ids = np.where(train_data_np[:, 3] == 1)[0]\n",
    "    train_readmit_row_ids[hospital_id] = train_readmit_patients_row_ids\n",
    "    \n",
    "    test_data_np = test_data.to_numpy()\n",
    "    test_readmit_patients_row_ids = np.where(test_data_np[:, 3] == 1)[0]\n",
    "    test_readmit_row_ids[hospital_id] = test_readmit_patients_row_ids\n",
    "    \n",
    "    # Label death in readmission\n",
    "    y_death_train = train_data.iloc[train_readmit_patients_row_ids, 2].to_numpy()\n",
    "    y_death_test = test_data.iloc[test_readmit_patients_row_ids, 2].to_numpy()\n",
    "    train_label_deaths[hospital_id] = y_death_train\n",
    "    test_label_deaths[hospital_id] = y_death_test\n",
    "    \n",
    "    # # Label readmission interval\n",
    "    # y_readmit_train = train_data.iloc[train_readmit_patients_row_ids, 3].to_numpy()\n",
    "    # y_readmit_test = test_data.iloc[test_readmit_patients_row_ids, 3].to_numpy()\n",
    "    # \n",
    "    # threshold = readmit_interval_threshold[hospital_id]\n",
    "    # \n",
    "    # y_readmit_train = np.where(y_readmit_train <= threshold, 1, 0)\n",
    "    # y_readmit_test = np.where(y_readmit_test <= threshold, 1, 0)\n",
    "    # \n",
    "    # train_label_readmit[hospital_id] = y_readmit_train\n",
    "    # test_label_readmit[hospital_id] = y_readmit_test\n",
    "\n",
    "\n",
    "icd_code_names = icd_data.columns[4:]\n",
    "icd_code_names"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-08T07:47:33.884255Z",
     "start_time": "2024-12-08T07:47:17.937016Z"
    }
   },
   "id": "fffd5f7c3546dd75",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "train_data_total = icd_data\n",
    "x_train = train_data_total.iloc[:, 4:].to_numpy()\n",
    "x_bow_train = []\n",
    "for row in x_train:\n",
    "    word_id = list(np.where(row == 1)[0])\n",
    "    x_bow_train.append(word_id)\n",
    "\n",
    "# Train Word2Vec embeddings\n",
    "# word2vec_model = Word2Vec(sentences=x_bow_train, vector_size=rho_size, window=5, min_count=1, sg=1)\n",
    "# pretrained_rho = word2vec_model.wv.vectors\n",
    "# pretrained_rho_tensor = torch.tensor(pretrained_rho, dtype=torch.float32)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-08T07:47:34.067016Z",
     "start_time": "2024-12-08T07:47:33.900867Z"
    }
   },
   "id": "8dd73b44519d8ca2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def convert_icd9_to_disease(icd_9):\n",
    "    if pd.isna(icd_9):\n",
    "        return \"Others\"\n",
    "    primary_icd9 = icd_9.split(',')[0].strip()\n",
    "    try:\n",
    "        # Convert the input to a float to handle both numeric and decimal ICD-9 codes\n",
    "        icd_9_float = float(primary_icd9)\n",
    "\n",
    "        # Check the ICD-9 code against the known ranges\n",
    "        if 1 <= icd_9_float <= 139.9:\n",
    "            return \"Infection\"\n",
    "        elif 140 <= icd_9_float <= 239.9:\n",
    "            return \"Neoplasms\"\n",
    "        elif 240 <= icd_9_float <= 279.9:\n",
    "            return \"Endocrine\"\n",
    "        elif 280 <= icd_9_float <= 289.9:\n",
    "            return \"Blood\"\n",
    "        elif 290 <= icd_9_float <= 319:\n",
    "            return \"Mental\"\n",
    "        elif 320 <= icd_9_float <= 389.9:\n",
    "            return \"Nervous\"\n",
    "        elif 390 <= icd_9_float <= 459.9:\n",
    "            return \"Circulatory\"\n",
    "        elif 460 <= icd_9_float <= 519.9:\n",
    "            return \"Respiratory\"\n",
    "        elif 520 <= icd_9_float <= 579.9:\n",
    "            return \"Digestive\"\n",
    "        elif 580 <= icd_9_float <= 629.9:\n",
    "            return \"Genitourinary\"\n",
    "        elif 630 <= icd_9_float <= 676.9:\n",
    "            return \"Pregnancy\"\n",
    "        elif 680 <= icd_9_float <= 709.9:\n",
    "            return \"Skin\"\n",
    "        elif 710 <= icd_9_float <= 739.9:\n",
    "            return \"Musculoskeletal\"\n",
    "        elif 740 <= icd_9_float <= 759.9:\n",
    "            return \"Congenital\"\n",
    "        elif 760 <= icd_9_float <= 799.9:\n",
    "            return \"Perinatal\"\n",
    "        elif 800 <= icd_9_float <= 1000:\n",
    "            return \"Poisoning\"\n",
    "        elif icd_9.startswith(\"V\"):\n",
    "            return \"Others\"\n",
    "        else:\n",
    "            return \"Others\"\n",
    "    \n",
    "    except ValueError:\n",
    "        return \"Others\"\n",
    "\n",
    "disease_color_map = {\n",
    "    \"Infection\": \"#005896\",\n",
    "    \"Neoplasms\": \"#dc5f00\",      # SteelBlue\n",
    "    \"Endocrine\": \"#008002\",      # LimeGreen\n",
    "    \"Blood\": \"#b40005\",          # Crimson\n",
    "    \"Mental\": \"#74499c\",         # DarkViolet\n",
    "    \"Nervous\": \"#6c382e\",        # Gold\n",
    "    \"Circulatory\": \"#ab3db3\",    # OrangeRed\n",
    "    \"Respiratory\": \"#2e2e2e\",    # DarkTurquoise\n",
    "    \"Digestive\": \"#9c9c00\",      # DeepPink\n",
    "    \"Genitourinary\": \"#009eac\",  # MediumSlateBlue\n",
    "    \"Pregnancy\": \"#abcc25\",      # HotPink\n",
    "    \"Skin\": \"#f06e60\",           # SaddleBrown\n",
    "    \"Musculoskeletal\": \"#3bd156\",# DarkOliveGreen\n",
    "    \"Congenital\": \"#c7b228\",     # BlueViolet\n",
    "    \"Perinatal\": \"#ff5c7c\",      # IndianRed\n",
    "    \"Poisoning\": \"#1268fd\",      # DarkOrange\n",
    "    \"Others\": \"#696969\",         # DimGray\n",
    "    \"Unknown\": \"#808080\"         # Gray\n",
    "}\n",
    "\n",
    "hospital_color_map = {\n",
    "    1001: \"#1268fd\",\n",
    "    2001: \"#ff5c7c\",\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-08T07:47:33.904039Z"
    }
   },
   "id": "6f1aad4e2e0c8a8d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "icd_code_dict = dict() # Key: disease category, Value: list of ICD codes\n",
    "for icd_code in icd_code_names:\n",
    "    disease = convert_icd9_to_disease(icd_code)\n",
    "    if disease in icd_code_dict:\n",
    "        icd_code_dict[disease].append(icd_code)\n",
    "    else:\n",
    "        icd_code_dict[disease] = [icd_code]\n",
    "\n",
    "icd_code_dict"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-08T07:47:33.905876Z"
    }
   },
   "id": "74e08cf82617b89d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "patient_icd_data = icd_data.iloc[:, 4:]\n",
    "\n",
    "total_feature_sum_dict = {}\n",
    "for feature in patient_icd_data.columns:\n",
    "    \n",
    "    feature_sum = patient_icd_data[feature].sum()\n",
    "    feature_name = convert_icd9_to_disease(feature)\n",
    "    print(f\"{feature_name}: {feature_sum}\")\n",
    "    \n",
    "    if feature_name in total_feature_sum_dict:\n",
    "        total_feature_sum_dict[feature_name] += feature_sum\n",
    "    else:\n",
    "        total_feature_sum_dict[feature_name] = feature_sum\n",
    "        \n",
    "print(total_feature_sum_dict)\n",
    "\n",
    "total_feature_sum_list = []\n",
    "for feature in patient_icd_data.columns:\n",
    "    \n",
    "    feature_name = convert_icd9_to_disease(feature)\n",
    "    feature_sum = total_feature_sum_dict[feature_name]\n",
    "    total_feature_sum_list.append(feature_sum)\n",
    "    \n",
    "feature_sums_tensor = torch.tensor(total_feature_sum_list)\n",
    "feature_sums_tensor"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-08T07:47:33.906420Z"
    }
   },
   "id": "1b0c413b5afa87df",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def find_common_icds(input, feature_sums_tensor):\n",
    "    \n",
    "    most_common_icd_names = []\n",
    "    least_common_icd_names = []\n",
    "\n",
    "    for row in input:\n",
    "        \n",
    "        active_indices = (row == 1).nonzero(as_tuple=True)[0].cpu().numpy()\n",
    "\n",
    "        if len(active_indices) == 0:\n",
    "            least_common_icd_names.append(\"Others\")\n",
    "        else:\n",
    "            active_sums = feature_sums_tensor[active_indices]\n",
    "            _, max_idx = torch.max(active_sums, dim=0)\n",
    "            most_common_feature_idx = active_indices[max_idx]\n",
    "            most_common_feature_icd = patient_icd_data.columns[most_common_feature_idx.item()]\n",
    "            most_common_feature_name = convert_icd9_to_disease(most_common_feature_icd)\n",
    "\n",
    "            most_common_icd_names.append(most_common_feature_name)\n",
    "\n",
    "            _, min_idx = torch.min(active_sums, dim=0)\n",
    "            least_common_feature_idx = active_indices[min_idx]\n",
    "            least_common_feature_icd = patient_icd_data.columns[least_common_feature_idx.item()]\n",
    "            least_common_feature_name = convert_icd9_to_disease(least_common_feature_icd)\n",
    "\n",
    "            least_common_icd_names.append(least_common_feature_name)\n",
    "\n",
    "    return most_common_icd_names, least_common_icd_names"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-08T07:47:33.909749Z"
    }
   },
   "id": "226625c9fdf5f65d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_topic_diversity(beta, topk):\n",
    "    num_topics = beta.shape[0]\n",
    "    list_w = np.zeros((num_topics, topk))\n",
    "    for k in range(num_topics):\n",
    "        idx = beta[k, :].argsort()[-topk:][::-1]\n",
    "        list_w[k, :] = idx\n",
    "    n_unique = len(np.unique(list_w))\n",
    "    TD = n_unique / (topk * num_topics)\n",
    "    return TD\n",
    "\n",
    "def get_topic_coherence(beta, data, topk):\n",
    "    D = len(data)  ## number of docs...data is list of documents\n",
    "    TC = []\n",
    "    num_topics = len(beta)\n",
    "    counter = 0\n",
    "    for k in range(num_topics):\n",
    "        top_10 = list(beta[k].argsort()[-topk:][::-1])\n",
    "        TC_k = 0\n",
    "        for i, word in enumerate(top_10):\n",
    "            # get D(w_i)\n",
    "            D_wi = get_document_frequency(data, word)\n",
    "            j = i + 1\n",
    "            tmp = 0\n",
    "            while j < len(top_10) and j > i:\n",
    "                # get D(w_j) and D(w_i, w_j)\n",
    "                D_wj, D_wi_wj = get_document_frequency(data, word, top_10[j])\n",
    "                # get f(w_i, w_j)\n",
    "                if D_wi_wj == 0:\n",
    "                    f_wi_wj = -1\n",
    "                else:\n",
    "                    f_wi_wj = -1 + (np.log(D_wi) + np.log(D_wj) - 2.0 * np.log(D)) / (np.log(D_wi_wj) - np.log(D))\n",
    "                # update tmp:\n",
    "                tmp += f_wi_wj\n",
    "                j += 1\n",
    "                counter += 1\n",
    "            # update TC_k\n",
    "            TC_k += tmp\n",
    "        TC.append(TC_k)\n",
    "    TC = np.mean(TC) / counter\n",
    "    TC = (TC + 1) / 2\n",
    "    return TC\n",
    "\n",
    "# def get_topic_diversity_by_icd_category(beta, topk):\n",
    "#     num_topics = beta.shape[0]\n",
    "#     total_categories = 17\n",
    "#     unique_categories = set()\n",
    "#     for k in range(num_topics):\n",
    "#         top_indices = beta[k].argsort()[-topk:][::-1]\n",
    "#         top_icd_codes = icd_code_names[top_indices]\n",
    "#         categories = [convert_icd9_to_disease(code) for code in top_icd_codes]\n",
    "#         unique_categories.update(categories)\n",
    "#         \n",
    "#     TD = len(unique_categories) / total_categories\n",
    "#     return TD\n",
    "\n",
    "def get_topic_coherence_by_icd_category(beta, topk):\n",
    "    \n",
    "    total_topic_coherence = 0\n",
    "    num_topics = len(beta)\n",
    "    for k in range(num_topics):\n",
    "        top_indices = beta[k].argsort()[-topk:][::-1]\n",
    "        top_icd_codes = icd_code_names[top_indices]\n",
    "        categories = [convert_icd9_to_disease(code) for code in top_icd_codes]\n",
    "        \n",
    "        same_category_count = 0\n",
    "        total_pairs = 0\n",
    "        \n",
    "        for i in range(len(categories)):\n",
    "            for j in range(i + 1, len(categories)):\n",
    "                total_pairs += 1\n",
    "                if categories[i] == categories[j]:\n",
    "                    same_category_count += 1\n",
    "        \n",
    "        topic_coherence = same_category_count / total_pairs if total_pairs > 0 else 0\n",
    "        total_topic_coherence += topic_coherence\n",
    "        \n",
    "    return total_topic_coherence / num_topics\n",
    "\n",
    "def get_document_frequency(data, wi, wj=None):\n",
    "    if wj is None:\n",
    "        D_wi = 0\n",
    "        for l in range(len(data)):\n",
    "            doc = data[l]\n",
    "            if wi in doc:\n",
    "                D_wi += 1\n",
    "        return D_wi\n",
    "    D_wj = 0\n",
    "    D_wi_wj = 0\n",
    "    for l in range(len(data)):\n",
    "        doc = data[l]\n",
    "        if wj in doc:\n",
    "            D_wj += 1\n",
    "            if wi in doc:\n",
    "                D_wi_wj += 1\n",
    "    return D_wj, D_wi_wj\n",
    "\n",
    "def top_k_precision(y_true, y_probs, k=3):\n",
    "    top_k_indices = np.argsort(y_probs)[-k:]\n",
    "    true_positives_in_top_k = np.sum(y_true[top_k_indices])\n",
    "    top_k_precision = true_positives_in_top_k / k\n",
    "    return top_k_precision"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-08T07:47:33.924353Z"
    }
   },
   "id": "9acff6d6ceb23f96",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def topic_diversity_regularizer(topic_matrix, threshold=0.1):\n",
    "    # num_topics = topic_matrix.size(0)\n",
    "    # diversity_penalty = 0\n",
    "    # for i in range(num_topics):\n",
    "    #     for j in range(i + 1, num_topics):\n",
    "    #         similarity = F.cosine_similarity(topic_matrix[i], topic_matrix[j], dim=0)\n",
    "    #         diversity_penalty += torch.max(torch.tensor(0.0), similarity - threshold)\n",
    "    # return diversity_penalty\n",
    "    normalized_topic_matrix = F.normalize(topic_matrix, p=2, dim=1)\n",
    "    cosine_sim_matrix = torch.matmul(normalized_topic_matrix, normalized_topic_matrix.t())\n",
    "    mask = torch.eye(cosine_sim_matrix.size(0), device=cosine_sim_matrix.device).bool()\n",
    "    cosine_sim_matrix = cosine_sim_matrix.masked_fill(mask, 0)\n",
    "    diversity_penalty = torch.sum(torch.relu(cosine_sim_matrix - threshold)) / 2\n",
    "    return diversity_penalty"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-08T07:47:34.264086Z"
    }
   },
   "id": "43fa4eaf9eebd03c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "disease_labels = [convert_icd9_to_disease(x) for x in icd_code_names]\n",
    "disease_labels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-08T07:47:34.266229Z"
    }
   },
   "id": "b0e8a573bf4d03af",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ETM(nn.Module):\n",
    "    def __init__(self, num_topics, vocab_size, t_hidden_size, rho_size, enc_drop=0.5):\n",
    "        super(ETM, self).__init__()\n",
    "\n",
    "        ## define hyperparameters\n",
    "        self.num_topics = num_topics\n",
    "        self.vocab_size = vocab_size\n",
    "        self.rho_size = rho_size\n",
    "        self.enc_drop = enc_drop\n",
    "        self.t_drop = nn.Dropout(enc_drop)\n",
    "        \n",
    "        ## define the word embedding matrix \\rho\n",
    "        self.rho = nn.Linear(rho_size, vocab_size, bias=False)\n",
    "        \n",
    "        # with torch.no_grad():\n",
    "        #     self.rho.weight = nn.Parameter(pretrained_rho_tensor.T)\n",
    "        #     self.rho.weight.requires_grad = False\n",
    "\n",
    "        ## define the matrix containing the topic embeddings\n",
    "        self.alphas = nn.Linear(rho_size, num_topics, bias=False)\n",
    "    \n",
    "        ## define variational distribution for \\theta_{1:D} via amortizartion\n",
    "        # print(vocab_size, \" THE Vocabulary size is here \")\n",
    "        self.q_theta = nn.Sequential(\n",
    "                nn.Linear(vocab_size, t_hidden_size),\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "        \n",
    "        self.mu_q_theta = nn.Linear(t_hidden_size, num_topics, bias=True)\n",
    "        self.logsigma_q_theta = nn.Linear(t_hidden_size, num_topics, bias=True)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        \"\"\"Returns a sample from a Gaussian distribution via reparameterization.\n",
    "        \"\"\"\n",
    "        if self.training:\n",
    "            std = torch.exp(0.5 * logvar) \n",
    "            eps = torch.randn_like(std)\n",
    "            return eps.mul_(std).add_(mu)\n",
    "        else:\n",
    "            # During inference time, there is no need for random sampling. \n",
    "            # Instead, the model can use the mean directly, which is a point estimate of the latent variable\n",
    "            # This avoids unnecessary randomness during inference or testing.\n",
    "            return mu\n",
    "\n",
    "    def encode(self, bows):\n",
    "        \"\"\"Returns paramters of the variational distribution for \\theta.\n",
    "\n",
    "        input: bows\n",
    "                batch of bag-of-words...tensor of shape bsz x V\n",
    "        output: mu_theta, log_sigma_theta\n",
    "        \"\"\"\n",
    "        q_theta = self.q_theta(bows)\n",
    "        if self.enc_drop > 0:\n",
    "            q_theta = self.t_drop(q_theta)\n",
    "        mu_theta = self.mu_q_theta(q_theta)\n",
    "        logsigma_theta = self.logsigma_q_theta(q_theta)\n",
    "        kl_theta = -0.5 * torch.sum(1 + logsigma_theta - mu_theta.pow(2) - logsigma_theta.exp(), dim=-1).mean()\n",
    "        \n",
    "        return mu_theta, logsigma_theta, kl_theta\n",
    "\n",
    "    def get_beta(self):\n",
    "        \"\"\"\n",
    "        This generate the description as a defintion over words\n",
    "\n",
    "        Returns:\n",
    "            [type]: [description]\n",
    "        \"\"\"\n",
    "        try:\n",
    "            logit = self.alphas(self.rho.weight) # torch.mm(self.rho, self.alphas)\n",
    "        except:\n",
    "            logit = self.alphas(self.rho)\n",
    "        # logit = self.alphas(self.rho.weight.T)\n",
    "        beta = F.softmax(logit, dim=0).transpose(1, 0) ## softmax over vocab dimension\n",
    "        return beta\n",
    "\n",
    "    def get_theta(self, normalized_bows, is_train=True, d=1.0):\n",
    "        \"\"\"\n",
    "        getting the topic poportion for the document passed in the normalixe bow or tf-idf\"\"\"\n",
    "        mu_theta, logsigma_theta, kld_theta = self.encode(normalized_bows)\n",
    "        z = self.reparameterize(mu_theta, logsigma_theta)\n",
    "        theta = F.softmax(z, dim=-1)\n",
    "        if not is_train:\n",
    "            theta = F.softmax(z / d, dim=-1)\n",
    "        return z, theta, kld_theta\n",
    "\n",
    "    def decode(self, theta, beta):\n",
    "        \"\"\"compute the probability of topic given the document which is equal to theta^T ** B\n",
    "\n",
    "        Args:\n",
    "            theta ([type]): [description]\n",
    "            beta ([type]): [description]\n",
    "\n",
    "        Returns:\n",
    "            [type]: [description]\n",
    "        \"\"\"\n",
    "        res = torch.mm(theta, beta)\n",
    "        \n",
    "        almost_zeros = torch.full_like(res, 1e-6)\n",
    "        results_without_zeros = res.add(almost_zeros)\n",
    "        predictions = torch.log(results_without_zeros)\n",
    "        return predictions\n",
    "\n",
    "    def forward(self, bows, normalized_bows, theta=None, aggregate=True):\n",
    "        ## get \\theta\n",
    "        if theta is None:\n",
    "            _, theta, kld_theta = self.get_theta(normalized_bows)\n",
    "        else:\n",
    "            kld_theta = None\n",
    "\n",
    "        ## get \\beta\n",
    "        beta = self.get_beta()\n",
    "\n",
    "        ## get prediction loss\n",
    "        preds = self.decode(theta, beta)\n",
    "        recon_loss = -(preds * bows).sum(1)\n",
    "        if aggregate:\n",
    "            recon_loss = recon_loss.mean()\n",
    "        return recon_loss, kld_theta"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-08T07:47:34.266768Z"
    }
   },
   "id": "45b4090ca96aaab9",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def train(client_models, client_optimizers, epochs=20, beta_=0.05, lambda_=0.1):\n",
    "    \n",
    "    elbo_hist = {}\n",
    "    kld_hist = {}\n",
    "    recon_hist = {}\n",
    "    \n",
    "    tc_hist = {}\n",
    "    td_hist = {}\n",
    "    tq_hist = {}\n",
    "    \n",
    "    for client_id in hospital_ids:\n",
    "        \n",
    "        elbo_hist[client_id] = []\n",
    "        kld_hist[client_id] = []\n",
    "        recon_hist[client_id] = []\n",
    "        \n",
    "        tc_hist[client_id] = []\n",
    "        td_hist[client_id] = []\n",
    "        tq_hist[client_id] = []\n",
    "        \n",
    "        client_loader = train_loaders[client_id]\n",
    "        client_model = client_models[client_id]\n",
    "        client_optimizer = client_optimizers[client_id]\n",
    "        \n",
    "        epochs = train_epochs[client_id]\n",
    "        beta_ = 1 / epochs\n",
    "\n",
    "        for local_epoch in range(epochs):  # Local training epochs (can increase as needed)\n",
    "            \n",
    "            epoch_recon_likelihood = 0.0\n",
    "            epoch_kld = 0.0\n",
    "            epoch_elbo = 0.0\n",
    "            \n",
    "            client_model.train()\n",
    "            \n",
    "            for batch_idx, (bows, normalized_bows) in enumerate(client_loader):\n",
    "                bows = bows.to(device)\n",
    "                normalized_bows = normalized_bows.to(device)\n",
    "\n",
    "                client_optimizer.zero_grad()\n",
    "                recon_loss, kld_theta = client_model(bows, normalized_bows)\n",
    "                \n",
    "                # Increase topic diversity\n",
    "                # Based on paper: https://arxiv.org/pdf/1706.00359\n",
    "                diversity_penalty = topic_diversity_regularizer(client_model.get_beta())\n",
    "                \n",
    "                # Beta-VAE KL Annealing to prevent posterior collapse\n",
    "                kl_weight = min(1.0, local_epoch * beta_)\n",
    "                elbo_term = recon_loss + kld_theta\n",
    "                loss = recon_loss + kl_weight * kld_theta + lambda_ * diversity_penalty\n",
    "                loss.backward()\n",
    "                client_optimizer.step()\n",
    "                \n",
    "                epoch_recon_likelihood += -recon_loss.item()\n",
    "                epoch_kld += kld_theta.item()\n",
    "                epoch_elbo += -elbo_term.item()\n",
    "                \n",
    "            epoch_recon_likelihood /= len(client_loader)\n",
    "            epoch_kld /= len(client_loader)\n",
    "            epoch_elbo /= len(client_loader)\n",
    "            \n",
    "            elbo_hist[client_id].append(epoch_elbo)\n",
    "            kld_hist[client_id].append(epoch_kld)\n",
    "            recon_hist[client_id].append(epoch_recon_likelihood)\n",
    "        \n",
    "            # Evaluate\n",
    "            client_model.eval()\n",
    "            \n",
    "            beta = client_model.get_beta()\n",
    "            beta = beta.data.cpu().numpy()\n",
    "            \n",
    "            x_bow_test = x_bow_tests[client_id]\n",
    "            coherence = get_topic_coherence_by_icd_category(beta, 10)\n",
    "            diversity = get_topic_diversity(beta, 3)\n",
    "            quality = coherence * diversity\n",
    "            \n",
    "            tc_hist[client_id].append(coherence)\n",
    "            td_hist[client_id].append(diversity)\n",
    "            tq_hist[client_id].append(quality)\n",
    "    \n",
    "            print(f\"Round {local_epoch + 1}/{epochs} - Client: {client_id} - ELBO: {epoch_elbo:.4f} - Recon likelihood: {epoch_recon_likelihood:.4f} - KLD: {epoch_kld:.4f}, TC: {coherence:.4f}, TD: {diversity:.4f}, TQ: {quality:.4f}\")\n",
    "        \n",
    "    return client_models, elbo_hist, kld_hist, recon_hist, tc_hist, td_hist, tq_hist"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-08T07:47:34.275839Z",
     "start_time": "2024-12-08T07:47:34.268435Z"
    }
   },
   "id": "b56439e728fd121f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "client_models = {}\n",
    "client_optimizers = {}\n",
    "\n",
    "for client_id in hospital_ids:\n",
    "\n",
    "    client_model = ETM(num_topics=num_topics,\n",
    "                       vocab_size=len(icd_code_names),\n",
    "                       t_hidden_size=t_hidden_size,\n",
    "                       rho_size=rho_size,\n",
    "                       enc_drop=enc_drop).to(device)\n",
    "    client_models[client_id] = client_model\n",
    "\n",
    "    optimizer_fn = torch.optim.Adam(client_model.parameters(), lr=5e-5, weight_decay=5e-6)\n",
    "    client_optimizers[client_id] = optimizer_fn\n",
    "\n",
    "client_models, elbo_hist, kld_hist, recon_hist, tc_hist, td_hist, tq_hist = train(client_models, client_optimizers, epochs=100, beta_=0.02, lambda_=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-08T07:47:34.274177Z"
    }
   },
   "id": "1b0f04b28c849774",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot ELBO\n",
    "plt.title(\"ELBO of ETM (eICU)\")\n",
    "plt.plot(elbo_hist[1001])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"ELBO\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-08T07:47:34.287476Z"
    }
   },
   "id": "205964d67975770a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot ELBO\n",
    "plt.title(\"ELBO of ETM (MIMIC-III)\")\n",
    "plt.plot(elbo_hist[2001])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"ELBO\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-08T07:47:34.296630Z"
    }
   },
   "id": "56e68b4fae6c06b1",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Plot Reconstruction Likelihood\n",
    "plt.title(\"Reconstruction Likelihood of ETM (eICU)\")\n",
    "plt.plot(recon_hist[1001])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"E[logp(x|z)]\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-08T07:47:34.341217Z",
     "start_time": "2024-12-08T07:47:34.300154Z"
    }
   },
   "id": "8aeeb9abd67a18cd",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Plot Reconstruction Likelihood\n",
    "plt.title(\"Reconstruction Likelihood of ETM (MIMIC-III)\")\n",
    "plt.plot(recon_hist[2001])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"E[logp(x|z)]\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-08T07:47:34.321210Z"
    }
   },
   "id": "63755db3c6af36d8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Plot KL\n",
    "plt.title(\"KL[q(z|x) || p(z)] of ETM (eICU)\")\n",
    "plt.plot(kld_hist[1001])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"KL[q(z|x) || p(z)]\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-08T07:47:34.323007Z"
    }
   },
   "id": "15646a70494e6858",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Plot KL\n",
    "plt.title(\"KL[q(z|x) || p(z)] of ETM (MIMIC-III)\")\n",
    "plt.plot(kld_hist[2001])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"KL[q(z|x) || p(z)]\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-08T07:47:34.323510Z"
    }
   },
   "id": "b5e8fe57a9fd66d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Plot Topic Coherence\n",
    "plt.title(\"Topic Coherence of ETM (eICU)\")\n",
    "plt.plot(tc_hist[1001])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Topic Coherence\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-08T07:47:34.338220Z"
    }
   },
   "id": "b12079af947c99bf",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Plot Topic Coherence\n",
    "plt.title(\"Topic Coherence of ETM (MIMIC-III)\")\n",
    "plt.plot(tc_hist[2001])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Topic Coherence\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-08T07:47:34.356239Z",
     "start_time": "2024-12-08T07:47:34.355270Z"
    }
   },
   "id": "20cc67964be54d15",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Plot Topic Diversity\n",
    "plt.title(\"Topic Diversity of ETM (eICU)\")\n",
    "plt.plot(td_hist[1001])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Topic Diversity\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-08T07:47:34.416460Z",
     "start_time": "2024-12-08T07:47:34.357999Z"
    }
   },
   "id": "56cbbfd31c4da7c3",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Plot Topic Diversity\n",
    "plt.title(\"Topic Diversity of ETM (MIMIC-III)\")\n",
    "plt.plot(td_hist[2001])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Topic Diversity\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-08T07:47:34.385197Z"
    }
   },
   "id": "d6d23d691442a23",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Plot Topic Quality\n",
    "plt.title(\"Topic Quality (Coherence x Diversity) of ETM (eICU)\")\n",
    "plt.plot(tq_hist[1001])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Topic Quality\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-08T07:47:34.385376Z"
    }
   },
   "id": "513dc023373ac3b7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Plot Topic Quality\n",
    "plt.title(\"Topic Quality (Coherence x Diversity) of ETM (MIMIC-III)\")\n",
    "plt.plot(tq_hist[2001])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Topic Quality\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-08T07:47:34.385582Z"
    }
   },
   "id": "ba04dfbf3c623dbc",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "eicu_client_model = client_models[1001]\n",
    "eicu_topic_word_distribution = eicu_client_model.get_beta()\n",
    "eicu_topic_word_distribution = eicu_topic_word_distribution.data.cpu().numpy()\n",
    "\n",
    "total_top_icd_idx = np.zeros((eicu_topic_word_distribution.shape[0], 5))  # K x 5\n",
    "\n",
    "for topic in range(eicu_topic_word_distribution.shape[0]):\n",
    "    topic_icds = eicu_topic_word_distribution[topic, :]\n",
    "    top_icd_idx = np.flip(np.argsort(topic_icds))[:5]  # Top 5 ICD codes\n",
    "    total_top_icd_idx[topic] = top_icd_idx\n",
    "\n",
    "total_top_icd_idx = np.ravel(total_top_icd_idx).astype(int)\n",
    "\n",
    "eicu_total_top_icd = eicu_topic_word_distribution[:, total_top_icd_idx]\n",
    "eicu_total_top_icd = eicu_total_top_icd.T\n",
    "\n",
    "total_top_icd_names = icd_code_names[total_top_icd_idx]\n",
    "disease = [convert_icd9_to_disease(x) for x in total_top_icd_names]\n",
    "disease_label = [f\"{disease[i]} - {total_top_icd_names[i]}\" for i in range(len(disease))]\n",
    "\n",
    "plt.figure(figsize=(8, 10))\n",
    "\n",
    "# Plot heatmap\n",
    "plt.title(\"Heatmap of the Top 5 ICD Codes per Topic using ETM (eICU)\")\n",
    "ax = sns.heatmap(eicu_total_top_icd,\n",
    "            yticklabels=disease_label,\n",
    "            cmap='Reds', vmax=0.2)\n",
    "\n",
    "ax.set_yticklabels(ax.get_yticklabels(), fontsize=8)\n",
    "\n",
    "y_labels = plt.gca().get_yticklabels()\n",
    "for i, label in enumerate(y_labels):\n",
    "    color = disease_color_map[disease[i]]\n",
    "    label.set_color(color)\n",
    "    \n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-08T07:47:34.389821Z"
    }
   },
   "id": "bd9e9e6a5179cc8d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "mimic_client_model = client_models[2001]\n",
    "mimic_topic_word_distribution = mimic_client_model.get_beta()\n",
    "mimic_topic_word_distribution = mimic_topic_word_distribution.data.cpu().numpy()\n",
    "\n",
    "total_top_icd_idx = np.zeros((mimic_topic_word_distribution.shape[0], 5))  # K x 5\n",
    "\n",
    "for topic in range(mimic_topic_word_distribution.shape[0]):\n",
    "    topic_icds = mimic_topic_word_distribution[topic, :]\n",
    "    top_icd_idx = np.flip(np.argsort(topic_icds))[:5]  # Top 5 ICD codes\n",
    "    total_top_icd_idx[topic] = top_icd_idx\n",
    "\n",
    "total_top_icd_idx = np.ravel(total_top_icd_idx).astype(int)\n",
    "\n",
    "mimic_total_top_icd = mimic_topic_word_distribution[:, total_top_icd_idx]\n",
    "mimic_total_top_icd = mimic_total_top_icd.T\n",
    "\n",
    "total_top_icd_names = icd_code_names[total_top_icd_idx]\n",
    "disease = [convert_icd9_to_disease(x) for x in total_top_icd_names]\n",
    "disease_label = [f\"{disease[i]} - {total_top_icd_names[i]}\" for i in range(len(disease))]\n",
    "\n",
    "plt.figure(figsize=(8, 10))\n",
    "\n",
    "# Plot heatmap\n",
    "plt.title(\"Heatmap of the Top 5 ICD Codes per Topic using ETM (MIMIC-III)\")\n",
    "ax = sns.heatmap(mimic_total_top_icd,\n",
    "            yticklabels=disease_label,\n",
    "            cmap='Reds', vmax=0.2)\n",
    "\n",
    "ax.set_yticklabels(ax.get_yticklabels(), fontsize=8)\n",
    "\n",
    "y_labels = plt.gca().get_yticklabels()\n",
    "for i, label in enumerate(y_labels):\n",
    "    color = disease_color_map[disease[i]]\n",
    "    label.set_color(color)\n",
    "    \n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-08T07:47:34.392477Z"
    }
   },
   "id": "630b53dc44ca9cb5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "eicu_x_bow_test = x_bow_tests[1001]\n",
    "eicu_coherence = get_topic_coherence_by_icd_category(eicu_topic_word_distribution, 10)\n",
    "eicu_diversity = get_topic_diversity(eicu_topic_word_distribution, 3)\n",
    "eicu_quality = eicu_coherence * eicu_diversity\n",
    "\n",
    "print(\"eICU ETM Topic Coherence: \", eicu_coherence)\n",
    "print(\"eICU ETM Topic Diversity: \", eicu_diversity)\n",
    "print(\"eICU ETM Topic Quality: \", eicu_quality)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-08T07:47:34.400012Z"
    }
   },
   "id": "caf14944d710cf12",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "mimic_x_bow_test = x_bow_tests[2001]\n",
    "mimic_coherence = get_topic_coherence_by_icd_category(mimic_topic_word_distribution, 10)\n",
    "mimic_diversity = get_topic_diversity(mimic_topic_word_distribution, 3)\n",
    "mimic_quality = mimic_coherence * mimic_diversity\n",
    "\n",
    "print(\"MIMIC ETM Topic Coherence: \", mimic_coherence)\n",
    "print(\"MIMIC ETM Topic Diversity: \", mimic_diversity)\n",
    "print(\"MIMIC ETM Topic Quality: \", mimic_quality)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-08T07:47:34.407489Z"
    }
   },
   "id": "410e7c58b28eb176",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "icd_code_names"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-08T07:47:34.512566Z",
     "start_time": "2024-12-08T07:47:34.420472Z"
    }
   },
   "id": "ceaf494e0800cfc3",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "disease_labels = [convert_icd9_to_disease(x) for x in icd_code_names]\n",
    "disease_labels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-08T07:47:34.424330Z"
    }
   },
   "id": "5e2e7c1e921bf3",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import linkage\n",
    "\n",
    "mimic_client_model = client_models[2001]\n",
    "eicu_x_test_tensor = test_icds[1001]\n",
    "\n",
    "_, eicu_test_theta_unweighted, _ = mimic_client_model.get_theta(eicu_x_test_tensor)\n",
    "eicu_test_theta_unweighted = eicu_test_theta_unweighted.data.cpu().numpy()\n",
    "\n",
    "eicu_test_readmit_row_ids = test_readmit_row_ids[1001]\n",
    "X_eicu_test = eicu_test_theta_unweighted[eicu_test_readmit_row_ids]\n",
    "eicu_icd_input = eicu_x_test_tensor[eicu_test_readmit_row_ids]\n",
    "\n",
    "eicu_most_common_icd_names, eicu_least_common_icd_names = find_common_icds(eicu_icd_input, feature_sums_tensor)\n",
    "\n",
    "unique_diseases = np.unique(eicu_least_common_icd_names)\n",
    "row_colors = pd.Series(eicu_least_common_icd_names).map(disease_color_map).to_numpy()\n",
    "\n",
    "# Create a seaborn clustermap\n",
    "plt.clf()\n",
    "row_clusters = linkage(X_eicu_test, method='ward')\n",
    "col_clusters = linkage(X_eicu_test.T, method='ward')\n",
    "g = sns.clustermap(X_eicu_test, row_linkage=row_clusters, col_linkage=col_clusters, \n",
    "                   figsize=(5, 6),\n",
    "                   yticklabels=False, cmap='rocket_r',\n",
    "                   cbar_kws={'orientation': 'horizontal', 'pad': 0.1, 'shrink': 0.6},\n",
    "                   cbar_pos=(0.45, -0.05, 0.3, 0.02),\n",
    "                   row_colors=row_colors)\n",
    "\n",
    "g.fig.suptitle(f'Heatmap ETM Patient-Topic Mixture (MIMIC on eICU)',\n",
    "               fontsize=12, x=0.6, y=1.02)\n",
    "g.ax_heatmap.set_xlabel('Latent Dimension')\n",
    "g.ax_heatmap.set_ylabel('Patients')\n",
    "\n",
    "legend_patches = [plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=disease_color_map[disease],\n",
    "                             markersize=10, label=disease) for disease in unique_diseases]\n",
    "plt.legend(handles=legend_patches, title='Disease', bbox_to_anchor=(2.0, 12), loc='lower left', borderaxespad=0.)\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-08T07:47:34.426158Z"
    }
   },
   "id": "b5fda83a2a3f62c7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from scipy.stats import ranksums\n",
    "\n",
    "unique_diseases = icd_code_dict.keys()\n",
    "eicu_disease_p_values = {}\n",
    "\n",
    "eicu_disease_topic_p_values = np.zeros((len(unique_diseases), num_topics))\n",
    "\n",
    "for disease_idx, disease in enumerate(unique_diseases):\n",
    "    \n",
    "    # ICD codes for disease category\n",
    "    icd_codes = icd_code_dict[disease]\n",
    "    icd_code_idx = [np.where(icd_code_names == icd_code)[0][0] for icd_code in icd_codes]\n",
    "    eicu_icd_input_disease = eicu_icd_input[:, icd_code_idx]\n",
    "    \n",
    "    # Find the patients if the disease is present\n",
    "    patient_has_disease_indices = (eicu_icd_input_disease.sum(dim=1) > 0).nonzero(as_tuple=True)[0]\n",
    "    patient_no_disease_indices = (eicu_icd_input_disease.sum(dim=1) == 0).nonzero(as_tuple=True)[0]\n",
    "    patient_has_disease_indices = patient_has_disease_indices.cpu().numpy()\n",
    "    patient_no_disease_indices = patient_no_disease_indices.cpu().numpy()\n",
    "    \n",
    "    if len(patient_has_disease_indices) == 0 or len(patient_no_disease_indices) == 0:\n",
    "        continue\n",
    "    \n",
    "    smallest_p_value = np.inf\n",
    "    for topic in range(num_topics):\n",
    "        theta_topic = X_eicu_test[:, topic]\n",
    "        theta_topic_has_disease = theta_topic[patient_has_disease_indices]\n",
    "        theta_topic_no_disease = theta_topic[patient_no_disease_indices]\n",
    "        _, p_value = ranksums(theta_topic_has_disease, theta_topic_no_disease)\n",
    "        eicu_disease_topic_p_values[disease_idx][topic] = -np.log10(p_value)\n",
    "        if p_value < smallest_p_value:\n",
    "            smallest_p_value = p_value\n",
    "    \n",
    "    eicu_disease_p_values[disease] = -np.log10(smallest_p_value)\n",
    "    \n",
    "# MIMIC on eICU\n",
    "eicu_disease_p_values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-08T07:47:34.426333Z"
    }
   },
   "id": "425a949c64ab7a92",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "preg_other_idx = [idx for idx in range(len(unique_diseases)) if list(unique_diseases)[idx] == \"Pregnancy\" or list(unique_diseases)[idx] == \"Others\"]\n",
    "\n",
    "eicu_disease_topic_p_values = np.delete(eicu_disease_topic_p_values, preg_other_idx, axis=0)\n",
    "unique_diseases = np.delete(list(unique_diseases), preg_other_idx)\n",
    "\n",
    "plt.figure(figsize=(5, 6))\n",
    "ax = sns.heatmap(eicu_disease_topic_p_values, cmap='Reds', cbar=True, cbar_kws={'orientation': 'horizontal', 'pad': 0.12, 'shrink': 0.8})\n",
    "\n",
    "ax.set_yticklabels(unique_diseases, rotation=0)\n",
    "\n",
    "colorbar = ax.collections[0].colorbar\n",
    "colorbar.set_label(\"-log10(p-value)\")\n",
    "\n",
    "plt.xlabel('Topics')\n",
    "plt.title('ETM Significance of Disease-Topic Associations (MIMIC on eICU)')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-08T07:47:34.427361Z"
    }
   },
   "id": "4708ce70fd9193c1",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "list(unique_diseases)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-08T07:47:34.427652Z"
    }
   },
   "id": "3858ce6d01bf09b8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import linkage\n",
    "\n",
    "eicu_client_model = client_models[1001]\n",
    "mimic_x_test_tensor = test_icds[2001]\n",
    "\n",
    "_, mimic_test_theta_unweighted, _ = eicu_client_model.get_theta(mimic_x_test_tensor)\n",
    "mimic_test_theta_unweighted = mimic_test_theta_unweighted.data.cpu().numpy()\n",
    "mimic_test_readmit_row_ids = test_readmit_row_ids[2001]\n",
    "\n",
    "X_mimic_test = mimic_test_theta_unweighted[mimic_test_readmit_row_ids]\n",
    "mimic_icd_input = mimic_x_test_tensor[mimic_test_readmit_row_ids]\n",
    "\n",
    "mimic_most_common_icd_names, mimic_least_common_icd_names = find_common_icds(mimic_icd_input, feature_sums_tensor)\n",
    "\n",
    "unique_diseases = np.unique(mimic_least_common_icd_names)\n",
    "row_colors = pd.Series(mimic_least_common_icd_names).map(disease_color_map).to_numpy()\n",
    "\n",
    "# Create a seaborn clustermap\n",
    "plt.clf()\n",
    "row_clusters = linkage(X_mimic_test, method='ward')\n",
    "col_clusters = linkage(X_mimic_test.T, method='ward')\n",
    "g = sns.clustermap(X_mimic_test, row_linkage=row_clusters, col_linkage=col_clusters, \n",
    "                   figsize=(5, 6),\n",
    "                   yticklabels=False, cmap='rocket_r',\n",
    "                   cbar_kws={'orientation': 'horizontal', 'pad': 0.1, 'shrink': 0.6},\n",
    "                   cbar_pos=(0.45, -0.05, 0.3, 0.02),\n",
    "                   row_colors=row_colors)\n",
    "\n",
    "g.fig.suptitle(f'Heatmap ETM Patient-Topic Mixture (eICU on MIMIC)',\n",
    "               fontsize=12, x=0.6, y=1.02)\n",
    "g.ax_heatmap.set_xlabel('Latent Dimension')\n",
    "g.ax_heatmap.set_ylabel('Patients')\n",
    "\n",
    "legend_patches = [plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=disease_color_map[disease],\n",
    "                             markersize=10, label=disease) for disease in unique_diseases]\n",
    "plt.legend(handles=legend_patches, title='Disease', bbox_to_anchor=(2.0, 12), loc='lower left', borderaxespad=0.)\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-08T07:47:34.428899Z"
    }
   },
   "id": "2ce6b6bb23c07108",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from scipy.stats import ranksums\n",
    "\n",
    "unique_diseases = icd_code_dict.keys()\n",
    "mimic_disease_p_values = {}\n",
    "\n",
    "mimic_disease_topic_p_values = np.zeros((len(unique_diseases), num_topics))\n",
    "\n",
    "for disease_idx, disease in enumerate(unique_diseases):\n",
    "    \n",
    "    # ICD codes for disease category\n",
    "    icd_codes = icd_code_dict[disease]\n",
    "    icd_code_idx = [np.where(icd_code_names == icd_code)[0][0] for icd_code in icd_codes]\n",
    "    mimic_icd_input_disease = mimic_icd_input[:, icd_code_idx]\n",
    "    \n",
    "    # Find the patients if the disease is present\n",
    "    patient_has_disease_indices = (mimic_icd_input_disease.sum(dim=1) > 0).nonzero(as_tuple=True)[0]\n",
    "    patient_no_disease_indices = (mimic_icd_input_disease.sum(dim=1) == 0).nonzero(as_tuple=True)[0]\n",
    "    patient_has_disease_indices = patient_has_disease_indices.cpu().numpy()\n",
    "    patient_no_disease_indices = patient_no_disease_indices.cpu().numpy()\n",
    "    \n",
    "    if len(patient_has_disease_indices) == 0 or len(patient_no_disease_indices) == 0:\n",
    "        continue\n",
    "    \n",
    "    smallest_p_value = np.inf\n",
    "    for topic in range(num_topics):\n",
    "        theta_topic = X_mimic_test[:, topic]\n",
    "        theta_topic_has_disease = theta_topic[patient_has_disease_indices]\n",
    "        theta_topic_no_disease = theta_topic[patient_no_disease_indices]\n",
    "        _, p_value = ranksums(theta_topic_has_disease, theta_topic_no_disease)\n",
    "        mimic_disease_topic_p_values[disease_idx][topic] = -np.log10(p_value)\n",
    "        if p_value < smallest_p_value:\n",
    "            smallest_p_value = p_value\n",
    "    \n",
    "    mimic_disease_p_values[disease] = -np.log10(smallest_p_value)\n",
    "    \n",
    "# eICU on MIMIC\n",
    "mimic_disease_p_values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-08T07:47:34.494625Z"
    }
   },
   "id": "810009a408559475",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "preg_other_idx = [idx for idx in range(len(unique_diseases)) if list(unique_diseases)[idx] == \"Pregnancy\" or list(unique_diseases)[idx] == \"Others\"]\n",
    "\n",
    "mimic_disease_topic_p_values = np.delete(mimic_disease_topic_p_values, preg_other_idx, axis=0)\n",
    "unique_diseases = np.delete(list(unique_diseases), preg_other_idx)\n",
    "\n",
    "plt.figure(figsize=(5, 6))\n",
    "ax = sns.heatmap(mimic_disease_topic_p_values, cmap='Reds', cbar=True, cbar_kws={'orientation': 'horizontal', 'pad': 0.12, 'shrink': 0.8})\n",
    "\n",
    "ax.set_yticklabels(unique_diseases, rotation=0)\n",
    "\n",
    "colorbar = ax.collections[0].colorbar\n",
    "colorbar.set_label(\"-log10(p-value)\")\n",
    "\n",
    "plt.xlabel('Topics')\n",
    "plt.title('ETM Significance of Disease-Topic Associations (eICU on MIMIC)')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-08T07:47:34.494784Z"
    }
   },
   "id": "ebccc0cb17efb22c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, roc_curve, auc, average_precision_score, roc_auc_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "mimic_client_model = client_models[2001]\n",
    "\n",
    "mimic_x_train_tensor = train_icds[2001]\n",
    "eicu_x_test_tensor = test_icds[1001]\n",
    "\n",
    "_, mimic_train_theta_unweighted, _ = mimic_client_model.get_theta(mimic_x_train_tensor)\n",
    "_, eicu_test_theta_unweighted, _ = mimic_client_model.get_theta(eicu_x_test_tensor)\n",
    "\n",
    "mimic_train_theta_unweighted = mimic_train_theta_unweighted.data.cpu().numpy()\n",
    "eicu_test_theta_unweighted = eicu_test_theta_unweighted.data.cpu().numpy()\n",
    "\n",
    "mimic_train_readmit_row_ids = train_readmit_row_ids[2001]\n",
    "eicu_test_readmit_row_ids = test_readmit_row_ids[1001]\n",
    "\n",
    "X_mimic_train = mimic_train_theta_unweighted[mimic_train_readmit_row_ids]\n",
    "X_eicu_test = eicu_test_theta_unweighted[eicu_test_readmit_row_ids]\n",
    "\n",
    "y_mimic_death_train = train_label_deaths[2001]\n",
    "y_eicu_death_test = test_label_deaths[1001]\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=120)\n",
    "knn.fit(X_mimic_train, y_mimic_death_train)\n",
    "\n",
    "y_eicu_death_cross_knn_scores = knn.predict_proba(X_eicu_test)[:, 1]\n",
    "\n",
    "precision_eicu_death_cross_knn, recall_eicu_death_cross_knn, _ = precision_recall_curve(y_eicu_death_test, y_eicu_death_cross_knn_scores)\n",
    "auprc_eicu_death_cross_knn = average_precision_score(y_eicu_death_test, y_eicu_death_cross_knn_scores)\n",
    "top_k_precision_death_cross_knn = top_k_precision(y_eicu_death_test, y_eicu_death_cross_knn_scores, k=100)\n",
    "\n",
    "fpr_eicu_death_cross_knn, tpr_eicu_death_cross_knn, _ = roc_curve(y_eicu_death_test, y_eicu_death_cross_knn_scores)\n",
    "auroc_eicu_death_cross_knn = roc_auc_score(y_eicu_death_test, y_eicu_death_cross_knn_scores)\n",
    "\n",
    "# Print the AUPRC and AUROC values\n",
    "print(f\"AUPRC of Mortality Prediction after Re-admission (MIMIC on eICU): {auprc_eicu_death_cross_knn:.4f}\")\n",
    "print(f\"AUROC of Mortality Prediction after Re-admission (MIMIC on eICU): {auroc_eicu_death_cross_knn:.4f}\")\n",
    "print(f\"Top k Precision of Mortality Prediction after Re-admission (MIMIC on eICU): {top_k_precision_death_cross_knn:.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-08T07:47:34.496224Z"
    }
   },
   "id": "7282a8b28356c07b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, auc, average_precision_score, roc_auc_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "eicu_client_model = client_models[1001]\n",
    "\n",
    "eicu_x_train_tensor = train_icds[1001]\n",
    "mimic_x_test_tensor = test_icds[2001]\n",
    "\n",
    "_, eicu_train_theta_unweighted, _ = eicu_client_model.get_theta(eicu_x_train_tensor)\n",
    "_, mimic_test_theta_unweighted, _ = eicu_client_model.get_theta(mimic_x_test_tensor)\n",
    "\n",
    "eicu_train_theta_unweighted = eicu_train_theta_unweighted.data.cpu().numpy()\n",
    "mimic_test_theta_unweighted = mimic_test_theta_unweighted.data.cpu().numpy()\n",
    "\n",
    "eicu_train_readmit_row_ids = train_readmit_row_ids[1001]\n",
    "mimic_test_readmit_row_ids = test_readmit_row_ids[2001]\n",
    "\n",
    "X_eicu_train = eicu_train_theta_unweighted[eicu_train_readmit_row_ids]\n",
    "X_mimic_test = mimic_test_theta_unweighted[mimic_test_readmit_row_ids]\n",
    "\n",
    "y_eicu_death_train = train_label_deaths[1001]\n",
    "y_mimic_death_test = test_label_deaths[2001]\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=120)\n",
    "knn.fit(X_eicu_train, y_eicu_death_train)\n",
    "\n",
    "y_mimic_death_cross_knn_scores = knn.predict_proba(X_mimic_test)[:, 1]\n",
    "\n",
    "precision_mimic_death_cross_knn, recall_mimic_death_cross_knn, _ = precision_recall_curve(y_mimic_death_test, y_mimic_death_cross_knn_scores)\n",
    "auprc_mimic_death_cross_knn = average_precision_score(y_mimic_death_test, y_mimic_death_cross_knn_scores)\n",
    "top_k_precision_mimic_cross_knn = top_k_precision(y_mimic_death_test, y_mimic_death_cross_knn_scores, k=100)\n",
    "\n",
    "fpr_mimic_death_cross_knn, tpr_mimic_death_cross_knn, _ = roc_curve(y_mimic_death_test, y_mimic_death_cross_knn_scores)\n",
    "auroc_mimic_death_cross_knn = roc_auc_score(y_mimic_death_test, y_mimic_death_cross_knn_scores)\n",
    "\n",
    "print(f\"AUPRC of Mortality Prediction after Re-admission (eICU on MIMIC): {auprc_mimic_death_cross_knn:.4f}\")\n",
    "print(f\"AUROC of Mortality Prediction after Re-admission (eICU on MIMIC): {auroc_mimic_death_cross_knn:.4f}\")\n",
    "print(f\"Top k Precision of Mortality Prediction after Re-admission (eICU on MIMIC): {top_k_precision_mimic_cross_knn:.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-08T07:47:34.496402Z"
    }
   },
   "id": "4362c9997858b4cc",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "with open(\"etm_recall_eicu_death_cross_knn_values.txt\", \"w\") as f:\n",
    "    for r in recall_eicu_death_cross_knn:\n",
    "        f.write(f\"{r}\\n\")\n",
    "        \n",
    "with open(\"etm_precision_eicu_death_cross_knn_values.txt\", \"w\") as f:\n",
    "    for p in precision_eicu_death_cross_knn:\n",
    "        f.write(f\"{p}\\n\")\n",
    "    \n",
    "with open(\"etm_auprc_eicu_death_cross_knn.txt\", \"w\") as f:\n",
    "    f.write(f\"{auprc_eicu_death_cross_knn}\\n\")\n",
    "\n",
    "with open(\"etm_top_k_precision_eicu_cross_knn.txt\", \"w\") as f:\n",
    "    f.write(f\"{top_k_precision_death_cross_knn}\\n\")\n",
    "    \n",
    "with open(\"etm_fpr_eicu_death_cross_knn_values.txt\", \"w\") as f:\n",
    "    for fp in fpr_eicu_death_cross_knn:\n",
    "        f.write(f\"{fp}\\n\")\n",
    "        \n",
    "with open(\"etm_tpr_eicu_death_cross_knn_values.txt\", \"w\") as f:\n",
    "    for tp in tpr_eicu_death_cross_knn:\n",
    "        f.write(f\"{tp}\\n\")\n",
    "        \n",
    "with open(\"etm_auroc_eicu_death_cross_knn.txt\", \"w\") as f:\n",
    "    f.write(f\"{auroc_eicu_death_cross_knn}\\n\")\n",
    "    \n",
    "with open(\"etm_eicu_disease_p_values.txt\", 'w') as file:\n",
    "    for key, value in eicu_disease_p_values.items():\n",
    "        file.write(f'{key}: {value}\\n')\n",
    "        \n",
    "with open(\"etm_eicu_disease_topic_p_values.txt\", 'w') as file:\n",
    "    for row in eicu_disease_topic_p_values:\n",
    "        file.write(\" \".join(f\"{value:.5f}\" for value in row) + \"\\n\")\n",
    "        \n",
    "with open(\"etm_recall_mimic_death_cross_knn_values.txt\", \"w\") as f:\n",
    "    for r in recall_mimic_death_cross_knn:\n",
    "        f.write(f\"{r}\\n\")\n",
    "        \n",
    "with open(\"etm_precision_mimic_death_cross_knn_values.txt\", \"w\") as f:\n",
    "    for p in precision_mimic_death_cross_knn:\n",
    "        f.write(f\"{p}\\n\")\n",
    "    \n",
    "with open(\"etm_auprc_mimic_death_cross_knn.txt\", \"w\") as f:\n",
    "    f.write(f\"{auprc_mimic_death_cross_knn}\\n\")\n",
    "    \n",
    "with open(\"etm_top_k_precision_mimic_cross_knn.txt\", \"w\") as f:\n",
    "    f.write(f\"{top_k_precision_mimic_cross_knn}\\n\")\n",
    "    \n",
    "with open(\"etm_mimic_disease_p_values.txt\", 'w') as file:\n",
    "    for key, value in mimic_disease_p_values.items():\n",
    "        file.write(f'{key}: {value}\\n')\n",
    "        \n",
    "with open(\"etm_fpr_mimic_death_cross_knn_values.txt\", \"w\") as f:\n",
    "    for fp in fpr_mimic_death_cross_knn:\n",
    "        f.write(f\"{fp}\\n\")\n",
    "        \n",
    "with open(\"etm_tpr_mimic_death_cross_knn_values.txt\", \"w\") as f:\n",
    "    for tp in tpr_mimic_death_cross_knn:\n",
    "        f.write(f\"{tp}\\n\")\n",
    "        \n",
    "with open(\"etm_auroc_mimic_death_cross_knn.txt\", \"w\") as f:\n",
    "    f.write(f\"{auroc_mimic_death_cross_knn}\\n\")\n",
    "\n",
    "with open(\"etm_mimic_disease_topic_p_values.txt\", 'w') as file:\n",
    "    for row in mimic_disease_topic_p_values:\n",
    "        file.write(\" \".join(f\"{value:.5f}\" for value in row) + \"\\n\")\n",
    "        \n",
    "with open(\"etm_unique_disease_names.txt\", 'w') as file:\n",
    "    for disease in unique_diseases:\n",
    "        file.write(f'{disease}\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-08T07:47:34.497426Z"
    }
   },
   "id": "4f05c8a587d814f2",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    " \n",
    "torch.save(client_models[2001].state_dict(), 'etm_mimic_client_model.pth')\n",
    "torch.save(client_models[1001].state_dict(), 'etm_eicu_client_model.pth')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "mimic_train_icds = train_icds[2001].cpu().numpy()\n",
    "np.save(\"etm_mimic_train_icds.npy\", mimic_train_icds)\n",
    "\n",
    "mimic_test_icds = test_icds[2001].cpu().numpy()\n",
    "np.save(\"etm_mimic_test_icds.npy\", mimic_test_icds)\n",
    "\n",
    "mimic_train_readmit_row_ids = train_readmit_row_ids[2001]\n",
    "np.save(\"etm_mimic_train_readmit_row_ids.npy\", mimic_train_readmit_row_ids)\n",
    "\n",
    "mimic_test_readmit_row_ids = test_readmit_row_ids[2001]\n",
    "np.save(\"etm_mimic_test_readmit_row_ids.npy\", mimic_test_readmit_row_ids)\n",
    "\n",
    "mimic_train_label_deaths = train_label_deaths[2001]\n",
    "np.save(\"etm_mimic_train_label_deaths.npy\", mimic_train_label_deaths)\n",
    "\n",
    "mimic_test_label_deaths = test_label_deaths[2001]\n",
    "np.save(\"etm_mimic_test_label_deaths.npy\", mimic_test_label_deaths)\n",
    "\n",
    "eicu_train_icds = train_icds[1001].cpu().numpy()\n",
    "np.save(\"etm_eicu_train_icds.npy\", eicu_train_icds)\n",
    "\n",
    "eicu_test_icds = test_icds[1001].cpu().numpy()\n",
    "np.save(\"etm_eicu_test_icds.npy\", eicu_test_icds)\n",
    "\n",
    "eicu_train_readmit_row_ids = train_readmit_row_ids[1001]\n",
    "np.save(\"etm_eicu_train_readmit_row_ids.npy\", eicu_train_readmit_row_ids)\n",
    "\n",
    "eicu_test_readmit_row_ids = test_readmit_row_ids[1001]\n",
    "np.save(\"etm_eicu_test_readmit_row_ids.npy\", eicu_test_readmit_row_ids)\n",
    "\n",
    "eicu_train_label_deaths = train_label_deaths[1001]\n",
    "np.save(\"etm_eicu_train_label_deaths.npy\", eicu_train_label_deaths)\n",
    "\n",
    "eicu_test_label_deaths = test_label_deaths[1001]\n",
    "np.save(\"etm_eicu_test_label_deaths.npy\", eicu_test_label_deaths)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-08T07:47:34.499256Z"
    }
   },
   "id": "74d3c6d8c8b4438f",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
